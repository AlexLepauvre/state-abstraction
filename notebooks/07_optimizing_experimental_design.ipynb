{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f0d1b0",
   "metadata": {},
   "source": [
    "# Optimizing experimental design\n",
    "\n",
    "To test whether participants rely on state abstraction for forward planning, we need to devise an experiment in which dynamic programing would be (presumably) too costly, such that participants have to rely on sub-optimal solution. At the same time, we need that experiment to enable us to discriminate between abstracted vs. ground MDP in participants behaviour. We will adjust the experimental parameters of the study by Ott and colleague. We have indeed seen that in that experiment, participants perform suboptimally, and also that we are able to discriminate quite well between different abstraction levels. However, we also found that the model without any abstraction still performed best. This might indicate that (1) participants do not rely on state abstraction to solve complex MDP or (2) that the size of the state space in that task wasn't large enough for participants to require to state abstraction, that they instead relied on the full MDP as well as some sort of heuristic as suggested in the original paper. \n",
    "\n",
    "To arbitrate between both options, we need to devise a task with a larger state space. We will do so by increasing the number of variables in the dimensions of our experiment. While we could do so blindly and hope for the best, we will instead optimize the experimental design for maximizing the distinction between abstraction level. Specifically, we will manipulate (1) the task parameters, (2) compute the state by state distance matrix of the resulting MDP, (3) compute decision values at various $\\epsilon$ abstraction levels, (4) compare the decision values between different abstraction levels and select the task that leads to the largest difference. This should be the task that makes it easiest to identify the abstraction level that participants might be using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e1955",
   "metadata": {},
   "source": [
    "## 1. Generating tasks\n",
    "First, we will generate different tasks with different parameters. We will primarily modulate the offers and costs levels to increase the state space size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9094e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import zscore\n",
    "from stabst.utils import plot_state_matrix, state_classes_from_lbl, avg_reduce_mdp, abstract2ground_value\n",
    "from scipy.special import expit\n",
    "from stabst.MarkovDecisionProcess import MDP\n",
    "from stabst.TaskConfig import LimitedEnergyTask\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "\n",
    "task_parameters = [\n",
    "    {\n",
    "        'name': 'original',\n",
    "        'O': [1, 2, 3, 4],\n",
    "        'p_offer': [1/4] * 4,\n",
    "        'C': [1, 2]\n",
    "    },\n",
    "    {\n",
    "        'name': '6 offers',\n",
    "        'O': [1, 2, 3, 4, 5, 6],\n",
    "        'p_offer': [1/6] * 6,\n",
    "        'C': [1, 2]\n",
    "    },\n",
    "    {\n",
    "        'name': '8 offers',\n",
    "        'O': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "        'p_offer': [1/8] * 8,\n",
    "        'C': [1, 2]\n",
    "    },\n",
    "    {\n",
    "        'name': '10 offers',\n",
    "        'O': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'p_offer': [1/10] * 10,\n",
    "        'C': [1, 2]\n",
    "    },\n",
    "    {\n",
    "        'name': '3 costs',\n",
    "        'O': [1, 2, 3, 4],\n",
    "        'p_offer': [1/4] * 4,\n",
    "        'C': [1, 2, 3]\n",
    "    },\n",
    "    {\n",
    "        'name': '4 costs',\n",
    "        'O': [1, 2, 3, 4],\n",
    "        'p_offer': [1/4] * 4,\n",
    "        'C': [1, 2, 3, 4]\n",
    "    },\n",
    "    {\n",
    "        'name': '6 costs',\n",
    "        'O': [1, 2, 3, 4],\n",
    "        'p_offer': [1/4] * 4,\n",
    "        'C': [1, 2, 3, 4, 5, 6]\n",
    "    },\n",
    "    {\n",
    "        'name': '6 costs & 10 offers',\n",
    "        'O': [1, 2, 3, 4, 6, 7, 8, 9, 10],\n",
    "        'p_offer': [1/10] * 10,\n",
    "        'C': [1, 2, 3, 4, 5, 6]\n",
    "    },\n",
    "]\n",
    "\n",
    "tasks = {}\n",
    "for tsk in task_parameters:\n",
    "    tasks[tsk['name']] = LimitedEnergyTask(O=tsk['O'], p_offer=tsk['p_offer'], C=tsk['C'])\n",
    "    tasks[tsk['name']].build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d41dd1",
   "metadata": {},
   "source": [
    "## 2 & 3 Compute state by state distance and compute decision values\n",
    "\n",
    "Now that we have generated the tasks, we can compute the distance matrix for each, abstract the MDPs based on the $\\epsilon$ distance and compute the decision values. Then, we will compare the decision values using correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382222a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.lepauvre\\AppData\\Local\\Temp\\ipykernel_41964\\2382234663.py:35: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n",
      "  0%|          | 2/1000 [1:19:11<569:53:42, 2055.73s/it] "
     ]
    }
   ],
   "source": [
    "# Set the abstraction levels to explore for each MDP:\n",
    "abstraction_level = np.arange(0.001, 0.1, 0.001)\n",
    "# Prepare dict to store the correlations:\n",
    "DV_correlations = []\n",
    "DV = {}\n",
    "# Loop through each task:\n",
    "for task_name, task in tasks.items():\n",
    "    # Create MDP:\n",
    "    task_mdp = MDP(task.states, task.tp, task.r, s2i=task.s2i)\n",
    "    n_states = len(task.states)\n",
    "    # Generate ground MDP decision values:\n",
    "    _, Q_full = task_mdp.backward_induction()\n",
    "    DV[0] = Q_full[:, 1] - Q_full[:, 0]\n",
    "    # Compute distance matrix:\n",
    "    if task_name == 'original':\n",
    "        distances_matrix = np.load('../data/bids/limited_energy/derivatives/state_abstraction/bisimulation_distance_matrix.npy')\n",
    "    else:\n",
    "        distances_matrix = task_mdp.bisim_metric(gamma=0.99, tol=1e-3, njobs=-1, max_iters=1000)\n",
    "    # Loop through each abstraction levels:\n",
    "    for eps in abstraction_level:\n",
    "        # Reduce the MDP accordingly:\n",
    "        abstract_mdp, state_classes, class_of_state = task_mdp.distance_reduce_mdp(eps, distance_matrix=distances_matrix)\n",
    "        n_states = len(abstract_mdp.states)\n",
    "        # Solve the MDP:\n",
    "        V_R, Q_R = abstract_mdp.backward_induction()\n",
    "        # Project back to Ground space:\n",
    "        V_from_abstract, Q_from_abstract = abstract2ground_value(class_of_state, V_R, Q_R)\n",
    "        # Compute the decision values:\n",
    "        DV[f\"{eps:.3f}\"] =  Q_from_abstract[:, 1] - Q_from_abstract[:, 0]\n",
    "    # Compute the correlation between each pairs of decision values:\n",
    "    corr_mat = np.zeros((len(DV), len(DV)))\n",
    "    for i, eps1 in enumerate(abstraction_level):\n",
    "        for ii, eps2 in enumerate(abstraction_level):\n",
    "            corr_mat[i, ii] = pearsonr(DV[f\"{eps1:.3f}\"], DV[f\"{eps2:.3f}\"]).statistic\n",
    "    DV_correlations.append(corr_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b8492",
   "metadata": {},
   "source": [
    "## 4 Visualization\n",
    "\n",
    "Now that we have computed the difference in decision values associated with each abstraction level for each task, we can visualize them to figure out whether one task shows stronger differences between them. Specifically, what we are after is a task for which the difference in decision values decreases the most rapidly as a function of $\\epsilon$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03554767",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tsk_i, tsk_param in enumerate(task_parameters):\n",
    "    # Plot the decision values:\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(DV_correlations[tsk_i], \n",
    "                   extent=[abstraction_level[0], abstraction_level[-1], \n",
    "                           abstraction_level[0], abstraction_level[-1]],\n",
    "                   cmap='RdYlBu_r');\n",
    "    ax.set_xlabel('Epsilon')\n",
    "    ax.set_ylabel('Epsilon')\n",
    "    ax.set_title(tsk_param['name'])\n",
    "    fig.colorbar(im, ax=ax, label=\"r\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
